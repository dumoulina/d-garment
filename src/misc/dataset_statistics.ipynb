{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import trimesh\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "from utils.uv_tools import apply_displacement\n",
    "from data.garment_dataset import GarmentDataset\n",
    "from data.amass_dataset import AmassDataset\n",
    "from utils.file_management import list_files\n",
    "from data.normalization import unnormalize_cloth\n",
    "from tqdm.contrib.concurrent import process_map  # or thread_map\n",
    "from utils.visualization import render, animation, imshow, plot_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../configs/config.json\") as f:\n",
    "    config = json.load(f)\n",
    "dataset = GarmentDataset(config, device=\"cuda:0\")\n",
    "body_model = dataset.body_model\n",
    "template = trimesh.Trimesh(dataset.template.v.cpu(), dataset.template.f.cpu(), vertex_colors=np.full_like(dataset.template.v.cpu(), (0.8,0.8,0.8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bending = [d['bending'] for d in dataset.lazy_data]\n",
    "stretching = [d['stretching'] for d in dataset.lazy_data]\n",
    "density = [d['density'] for d in dataset.lazy_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bending.sort()\n",
    "stretching.sort()\n",
    "density.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(density, np.linspace(density[0], density[-1], 50), histtype='bar', rwidth=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bending, np.linspace((bending[0]), (bending[-1]), 50), histtype='bar', color='orange')\n",
    "plt.hist(bending, np.logspace(np.log10(bending[0]), np.log10(bending[-1]), 50), histtype='step')\n",
    "\n",
    "plt.show() # should be uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(stretching, np.linspace(stretching[0], stretching[-1], 50), histtype='bar', rwidth=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices = dataset[0]['cloth_vertices'].cpu()\n",
    "print(vertices)\n",
    "ground_truth = trimesh.Trimesh(vertices, dataset.template.f.cpu(), vertex_colors=np.full_like(dataset.template.v.cpu(), (1,0,0)))\n",
    "# v = animation([ground_truth, template])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displaced = apply_displacement(dataset.template, dataset[0][\"vdm\"], dataset.img_size)\n",
    "\n",
    "displacement = displaced - dataset[0][\"cloth_vertices\"]\n",
    "norm = torch.linalg.vector_norm(displacement, dim=1)\n",
    "sort_norm = torch.argsort(norm)\n",
    "\n",
    "color = torch.tile(torch.tensor([[1.,0.,0.,1.]]), (norm.shape[0], 1))\n",
    "color [:,0] = color [:,0] * norm.cpu() * 1000\n",
    "color [color > 1.] = 1.\n",
    "color [color < 0.] = 0.\n",
    "\n",
    "gt = trimesh.Trimesh(dataset[0]['cloth_vertices'].cpu(), dataset.template.f.cpu(), vertex_colors=np.full_like(color, 1))\n",
    "mesh = trimesh.Trimesh(displaced.cpu(), dataset.template.f.cpu(), vertex_colors=color)\n",
    "template = trimesh.Trimesh(dataset.template.v.cpu(), dataset.template.f.cpu(), vertex_colors=np.full_like(color, 1))\n",
    "\n",
    "print(norm.max())\n",
    "print(norm.mean())\n",
    "print(norm.shape)\n",
    "print(dataset[0][\"vdm\"].shape)\n",
    "# (gt+mesh+template).show()\n",
    "mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = dataset.get_seq_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sequences.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = sequences['/home/adumouli/Data/MY_DATASET/Dataset/accad/walk/B1-standtowalk_poses/Cos/data0/output']\n",
    "SEQ_START = seq[0]\n",
    "SEQ_LEN = seq[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meshes = []\n",
    "datas = []\n",
    "conditions = []\n",
    "for i in range(SEQ_START, SEQ_START+SEQ_LEN, 10):\n",
    "    data = dataset[i]\n",
    "    datas.append(data)\n",
    "\n",
    "body_faces = body_model.get_faces().cpu()\n",
    "body_sequence = []\n",
    "ground_truth = []\n",
    "for i, data in enumerate(datas):\n",
    "    body_vertices = body_model(data)[-1].cpu()\n",
    "    body_sequence.append(trimesh.Trimesh(body_vertices, body_faces, vertex_colors=np.full_like(body_vertices, (1,1,1)), process=False))\n",
    "\n",
    "    data_cp = data.copy()\n",
    "    unnormalize_cloth(data_cp)\n",
    "    v = data_cp['cloth_vertices'].cpu()\n",
    "    ground_truth.append(trimesh.Trimesh(v, dataset.template.f.cpu(), vertex_colors=np.full_like(v, (1,1,1))*.5))\n",
    "\n",
    "print(len(body_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = trimesh.Scene()\n",
    "for i in range(0, len(body_sequence), 3):\n",
    "    scene.add_geometry(body_sequence[i] + ground_truth[i])\n",
    "    # trimesh.Trimesh().export(\"/home/adumouli/Bureau/sequence/full/frame_\" + str(i) + \".obj\")\n",
    "    # ground_truth[i].export(\"/home/adumouli/Bureau/sequence/ground_truth/frame_\" + str(i) + \".obj\")\n",
    "    # body_sequence[i].export(\"/home/adumouli/Bureau/sequence/body/frame_\" + str(i) + \".obj\")\n",
    "scene.show(viewer='gl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meshes = []\n",
    "for i in range(len(body_sequence)):\n",
    "    frame = body_sequence[i]\n",
    "    frame +=  ground_truth[i]\n",
    "    meshes.append(frame)\n",
    "\n",
    "animation(meshes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Body self-intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import trimesh\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "from utils.uv_tools import apply_displacement\n",
    "from data.garment_dataset import GarmentDataset\n",
    "from data.amass_dataset import AmassDataset\n",
    "from utils.file_management import list_files\n",
    "from data.normalization import unnormalize_cloth\n",
    "from tqdm.contrib.concurrent import process_map  # or thread_map\n",
    "from utils.visualization import render, Sequencevisualizer, imshow, plot_dict, save_video\n",
    "\n",
    "import time\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import trimesh\n",
    "import pyrender\n",
    "from mesh_intersection.bvh_search_tree import BVH\n",
    "from utils.file_management import list_files\n",
    "from data.smpl_sequence import SMPL_Sequence\n",
    "from body_models.smpl_model import SMPLH\n",
    "from tqdm.auto import tqdm\n",
    "from utils.geometry import l2dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compute smpl edge lengthes\n",
    "\n",
    "# zero_smpl = trimesh.load_mesh('/home/adumouli/Bureau/garment-diffusion/src/zero_smpl.obj')\n",
    "# # zero_smpl = zero_smpl.subdivide_loop(2)\n",
    "\n",
    "# color = torch.Tensor(zero_smpl.vertices)\n",
    "# length = torch.Tensor(zero_smpl.edges_unique_length)\n",
    "# color[zero_smpl.edges_unique] = length\n",
    "# trimesh.Trimesh(zero_smpl.vertices, zero_smpl.faces, vertex_colors=color).show(viewer='gl')\n",
    "\n",
    "# # color = torch.Tensor(zero_smpl.area_faces)[..., None].expand(-1,4).clone()\n",
    "# # color[:,0] *= 1e3\n",
    "# # color[:,1:3] = 0\n",
    "# # color[:,3] = 1\n",
    "# # trimesh.Trimesh(zero_smpl.vertices, zero_smpl.faces, face_colors=color).show(viewer='gl')\n",
    "\n",
    "# # plt.boxplot(zero_smpl.edges_unique_length);\n",
    "# # plt.boxplot(1/zero_smpl.area_faces);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/adumouli/Bureau/garment-diffusion/configs/config.json\") as f:\n",
    "    config = json.load(f)\n",
    "amass = AmassDataset(config)\n",
    "\n",
    "fixed_amass = AmassDataset(config, config[\"dataset\"][\"folder\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, seq in enumerate(amass):\n",
    "    if re.search(\"leap\", seq.npz_file) is not None:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute smpl native self-intersections\n",
    "\n",
    "device = 'cuda'\n",
    "m = BVH(max_collisions=8)\n",
    "\n",
    "# zero_smpl = trimesh.load_mesh('/home/adumouli/Bureau/garment-diffusion/src/zero_smpl.obj')\n",
    "# vertices = zero_smpl.vertices\n",
    "\n",
    "data = amass[0].data\n",
    "data['poses'] = torch.zeros_like(data['poses'])\n",
    "data['betas'] = torch.zeros_like(data['betas'])\n",
    "\n",
    "vertices = amass.body_model(data)[0]\n",
    "faces = amass.body_model.get_faces().cpu()\n",
    "triangle_count = float(faces.shape[0])\n",
    "\n",
    "triangles = vertices[faces]\n",
    "triangles = torch.Tensor(triangles).to(device)[None,...]\n",
    "\n",
    "outputs = m(triangles)\n",
    "mask = outputs[..., 0] >= 0\n",
    "collisions = outputs[mask]\n",
    "\n",
    "count_before = torch.count_nonzero(mask, dim=-1) * (100 / triangle_count)\n",
    "\n",
    "zero_intersections = count_before.detach().cpu()[0].item()\n",
    "\n",
    "print(zero_intersections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../log/amass_intersect_fix_30.pkl\", 'rb') as f:\n",
    "    previous = pickle.load(f)\n",
    "\n",
    "with open(\"../log/amass_intersect_fix_snug.pkl\", 'rb') as f:\n",
    "    result = pickle.load(f)\n",
    "\n",
    "previous_table = []\n",
    "for k in previous.keys():\n",
    "    previous_table.append(previous[k].mean())\n",
    "\n",
    "table = []\n",
    "for k in result.keys():\n",
    "    table.append(result[k].mean())\n",
    "\n",
    "fig,(ax) = plt.subplots(figsize=(4,4), ncols=1)\n",
    "# ax.set_title('Self-intersections distribution in selected AMASS sequences')\n",
    "ax.set_xlabel('Sequence')\n",
    "ax.set_ylabel('Intersecting face percentage')\n",
    "ax.plot(table, label='fix')\n",
    "ax.plot(previous_table, label='original')\n",
    "plt.axhline(y = zero_intersections, color = 'r', linestyle = '-', label='zero')\n",
    "ax.legend()\n",
    "\n",
    "fig,(ax) = plt.subplots(figsize=(4,4), ncols=1)\n",
    "# ax.set_title('Self-intersections distribution in selected AMASS sequences')\n",
    "ax.set_xlabel('Intersecting face percentage')\n",
    "ax.set_ylabel('Sequence count')\n",
    "ax.hist(table, alpha=0.5, label='fix')\n",
    "ax.hist(previous_table, alpha=0.5, label='original')\n",
    "plt.axvline(x = zero_intersections, color = 'r', linestyle = '-', label='zero')\n",
    "ax.legend()\n",
    "\n",
    "fig,(ax) = plt.subplots(figsize=(2,2), ncols=2)\n",
    "# ax.set_ylabel('Intersecting face percentage')\n",
    "ax[0].boxplot(previous_table)\n",
    "ax[0].set_ylabel('Intersecting face %')\n",
    "ax[0].set_xlabel('orig')\n",
    "ax[1].boxplot(table)\n",
    "ax[1].set_xlabel('fix')\n",
    "ax[1].get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../log/amass_fix_log_before.pkl\", 'rb') as f:\n",
    "    previous = pickle.load(f)\n",
    "\n",
    "with open(\"../log/amass_fix_log_new.pkl\", 'rb') as f:\n",
    "    result = pickle.load(f)\n",
    "\n",
    "previous_table = []\n",
    "for k in previous.keys():\n",
    "    previous_table.append(previous[k].mean())\n",
    "\n",
    "table = []\n",
    "for k in result.keys():\n",
    "    table.append(result[k].mean())\n",
    "\n",
    "fig,(ax) = plt.subplots(figsize=(4,4), ncols=1)\n",
    "# ax.set_title('Self-intersections distribution in selected AMASS sequences')\n",
    "ax.set_xlabel('Sequence')\n",
    "ax.set_ylabel('Intersecting face percentage')\n",
    "ax.plot(table, label='fix')\n",
    "ax.plot(previous_table, label='original')\n",
    "plt.axhline(y = zero_intersections, color = 'r', linestyle = '-', label='zero')\n",
    "ax.legend()\n",
    "\n",
    "fig,(ax) = plt.subplots(figsize=(4,4), ncols=1)\n",
    "# ax.set_title('Self-intersections distribution in selected AMASS sequences')\n",
    "ax.set_xlabel('Intersecting face percentage')\n",
    "ax.set_ylabel('Sequence count')\n",
    "ax.hist(table, alpha=0.5, label='fix')\n",
    "ax.hist(previous_table, alpha=0.5, label='original')\n",
    "plt.axvline(x = zero_intersections, color = 'r', linestyle = '-', label='zero')\n",
    "ax.legend()\n",
    "\n",
    "fig,(ax) = plt.subplots(figsize=(2,2), ncols=2)\n",
    "# ax.set_ylabel('Intersecting face percentage')\n",
    "ax[0].boxplot(previous_table)\n",
    "ax[0].set_ylabel('Intersecting face %')\n",
    "ax[0].set_xlabel('orig')\n",
    "ax[1].boxplot(table)\n",
    "ax[1].set_xlabel('fix')\n",
    "ax[1].get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dict(result, legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../log/amass_intersect_log.pkl\", 'rb') as f:\n",
    "    result = pickle.load(f)\n",
    "with open(\"../log/amass_intersect_fix_snug.pkl\", 'rb') as f:\n",
    "    new_result = pickle.load(f)\n",
    "# Create a list of tuples: (key, max_value, mean_value, frame_of_max)\n",
    "stats = []\n",
    "for k in result.keys():\n",
    "    max_val = result[k].max()\n",
    "    mean_val = result[k].mean()\n",
    "    frame_of_max = result[k].argmax()\n",
    "    diff = (result[k] - new_result[k]).min()\n",
    "    diff_idx = (result[k] - new_result[k]).argmin()\n",
    "    stats.append((k, max_val, mean_val, frame_of_max, diff, diff_idx))\n",
    "\n",
    "# Sort the list based on max_value in descending order\n",
    "sorted_stats = sorted(stats, key=lambda x: x[4], reverse=True)\n",
    "\n",
    "# Print the sorted keys and corresponding max values\n",
    "for k, max_val, mean_val, frame_of_max, diff, diff_idx in sorted_stats:\n",
    "    print(f\"Key: {k}, Max: {max_val:.4f}, Mean: {mean_val:.4f}, Frame: {frame_of_max}, Diff: {diff}:{diff_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = \"/home/adumouli/Data/MY_DATASET/SELECTED_AMASS\"\n",
    "file_list = list_files(out, pattern=\"poses.npz\")\n",
    "device = 'cuda'\n",
    "faces = amass.body_model.get_faces().cpu()\n",
    "number = 0\n",
    "key = sorted_stats[number][0]\n",
    "\n",
    "key = \"Running_c3d/C19\"\n",
    "for i, f in enumerate(file_list):\n",
    "    if re.search(key, f) is None:\n",
    "        continue\n",
    "    \n",
    "    print(f)\n",
    "    seq = SMPL_Sequence(f, device=device).to(device)\n",
    "    data = seq.data\n",
    "    data[\"poses\"] = data[\"poses\"][:, :66]\n",
    "    data[\"betas\"][1] = -2\n",
    "    verts = amass.body_model(data).cpu()\n",
    "    meshes = [trimesh.Trimesh(v, faces) for v in verts]\n",
    "\n",
    "    from utils.smpl_tools import separate_arms\n",
    "    data[\"poses\"] = separate_arms(data[\"poses\"], 20)\n",
    "    verts = amass.body_model(data).cpu()\n",
    "    for idx, v in enumerate(verts):\n",
    "\n",
    "        v[:,2] += 2\n",
    "        meshes[idx] += trimesh.Trimesh(v, faces)\n",
    "\n",
    "    viewer = Sequencevisualizer(meshes)\n",
    "    print(meshes)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax) = plt.subplots(figsize=(4,4), ncols=1)\n",
    "ax.set_title('KIT/348/walking_fast06')\n",
    "ax.set_xlabel('Frame')\n",
    "ax.set_ylabel('Intersecting face percentage')\n",
    "plt.plot(result[key])\n",
    "plt.axhline(y = 0.73, color = 'r', linestyle = '-')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mean, label='mean')\n",
    "plt.plot(maximum, label='max')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from body_models.smpl_model import SMPLH\n",
    "from data.smpl_sequence import SMPL_Sequence\n",
    "import json\n",
    "import torch\n",
    "import trimesh\n",
    "import pickle\n",
    "with open(\"./amass_fix_log_new.pkl\", 'rb') as f:\n",
    "    result = pickle.load(f)\n",
    "\n",
    "tmp = 0\n",
    "key = None\n",
    "for k in result.keys():\n",
    "    if result[k].max() > tmp:\n",
    "        tmp = result[k].max()\n",
    "        key = k\n",
    "\n",
    "with open(\"/home/adumouli/Bureau/garment-diffusion/configs/config.json\") as f:\n",
    "    config = json.load(f)\n",
    "    config[\"dtype\"] = torch.float32\n",
    "    # config[\"device\"] = 'cpu'\n",
    "    smplh = SMPLH(config)\n",
    "faces = smplh.get_faces().to(\"cpu\", torch.long)\n",
    "\n",
    "seq = SMPL_Sequence(key)\n",
    "data = dict()\n",
    "data[\"trans\"] = seq.data[\"trans\"].to(\"cuda\", dtype=torch.float32)\n",
    "data[\"poses\"] = seq.data[\"poses\"][:, :66].to(\"cuda\", dtype=torch.float32)\n",
    "data[\"betas\"] = seq.data[\"betas\"][None,...].to(\"cuda\", dtype=torch.float32)\n",
    "vertices = smplh(data).to(dtype=torch.float32).detach().cpu()\n",
    "\n",
    "sequence = [trimesh.Trimesh(i, faces) for i in vertices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = amass[0].data\n",
    "\n",
    "vertices = smplh(data).to(dtype=torch.float32).detach().cpu()\n",
    "sequence = [trimesh.Trimesh(i, faces) for i in vertices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import tempfile\n",
    "from PIL import Image\n",
    "from itertools import repeat\n",
    "import trimesh\n",
    "import pyrender\n",
    "from tqdm.contrib.concurrent import process_map  # or thread_map\n",
    "import numpy as np\n",
    "\n",
    "def _renderSeq(meshes: list[trimesh.Trimesh], folder):\n",
    "    renderer = pyrender.OffscreenRenderer(512, 512)\n",
    "    meshes = process_map(pyrender.Mesh.from_trimesh, meshes, max_workers=8)\n",
    "\n",
    "    table=[]\n",
    "\n",
    "    camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0, aspectRatio=1.414)\n",
    "    # camera = pyrender.OrthographicCamera(xmag=5.0, ymag=5.0)\n",
    "    light = pyrender.DirectionalLight(color=[1.0, 1.0, 1.0], intensity=2.0)\n",
    "    # grid = pyrender.Mesh.from_trimesh(trimesh.creation.box(extents=[20, 20, 0.01]))\n",
    "    # grid = pyrender.Mesh.from_points([[20,20,0], [20,-20,0],[-20,-20,0],[-20,20,0]], colors=[1,0,0]*4)\n",
    "    trimesh.transformations.rotation_matrix(np.pi/2, [0,0,1])\n",
    "    x=-np.pi/4\n",
    "    cam_pose = np.array([\n",
    "    [1.0, 0.0, 0.0, -1],\n",
    "    [0.0, np.cos(x), np.sin(x), -2],\n",
    "    [0.0, -np.sin(x), np.cos(x), 3],\n",
    "    [0.0, 0.0, 0.0, 1.0]\n",
    "    ])\n",
    "    for i, mesh in enumerate(meshes):\n",
    "        scene = pyrender.Scene(ambient_light=[0.02, 0.02, 0.02], bg_color=[1.0, 1.0, 1.0])\n",
    "        # cam_pose = trimesh.transformations.translation_matrix(mesh.centroid*[1, 1, 0]+[0,0,2])\n",
    "        scene.add(mesh, pose=np.eye(4))\n",
    "        scene.add(camera, pose=cam_pose)\n",
    "        scene.add(light, pose=np.eye(4))\n",
    "        arr, _ = renderer.render(scene)\n",
    "        img = Image.fromarray(arr)\n",
    "        img.save(os.path.join(folder, f\"img{i}.png\"))\n",
    "\n",
    "    renderer.delete()\n",
    "\n",
    "def save_video(sequence: list[trimesh.Trimesh], outputfile=\"./out.mp4\", fps=50):\n",
    "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "        _renderSeq(sequence, tmp_dir)\n",
    "        os.system(f\"ffmpeg -r {fps} -i {tmp_dir}/img%01d.png -b 5000k -vcodec h264 -y {outputfile}\")\n",
    "\n",
    "# save_video(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import trimesh\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "from data.garment_dataset import GarmentDataset\n",
    "from data.amass_dataset import AmassDataset\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "with open(\"/home/adumouli/Bureau/garment-diffusion/configs/config.json\") as f:\n",
    "    config = json.load(f)\n",
    "dataset = AmassDataset(config, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'poses' # change in ['betas', 'poses', 'trans']\n",
    "\n",
    "color = torch.empty(0)\n",
    "poses = np.empty((0, 66))\n",
    "body_verts = torch.empty(0)\n",
    "for seq in tqdm(range(len(dataset))):\n",
    "    data = dataset[seq].sequence_data(25)\n",
    "    # data = dataset[seq].data\n",
    "\n",
    "    # values = aa2six(data[key].reshape(data[key].shape[0],-1,3)).flatten(1,2)\n",
    "    values = data[key]\n",
    "    values = np.unwrap(values.cpu().numpy())\n",
    "    poses = np.append(poses, values, axis=0)\n",
    "\n",
    "    vertices = dataset.body_model(data)\n",
    "    body_verts = torch.cat((body_verts, vertices))\n",
    "\n",
    "    color = torch.cat((color, torch.rand((1, 3)).expand(values.shape[0], 3)))\n",
    "    \n",
    "color = color.cpu().numpy()\n",
    "body_verts = body_verts.cpu().flatten(1,2).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(poses.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(body_verts[...,0], body_verts[...,1], s=10, c=color, alpha=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(poses[...,0], poses[...,1], s=10, c=color, alpha=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(verbose=True)\n",
    "poses_tsne = tsne.fit_transform(poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(verbose=True)\n",
    "body_verts_tsne = tsne.fit_transform(body_verts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tsne(data, target=None):\n",
    "    \"\"\"\n",
    "    Visualize t-SNE 2 dimnetinal graph and use stratified target as the color\n",
    "\n",
    "    Parameters:\n",
    "    data: Input Array containing the output of T-SNE transformation\n",
    "    target: Input Array or Dataframe containing the stratified Target\n",
    "    \n",
    "    Returns:\n",
    "    t-SNE graph\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.scatter(data[:,0], data[:,1],\n",
    "            c=target, \n",
    "            edgecolor='none', \n",
    "            alpha=0.80, \n",
    "            s=10)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_tsne(body_verts_tsne, color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_tsne(poses_tsne, color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'poses' # change in ['betas', 'poses', 'trans']\n",
    "\n",
    "train_p = torch.empty(0)\n",
    "for seq in tqdm(range(3)):\n",
    "    # values = data[key]\n",
    "    train_p = torch.cat((train_p, values))\n",
    "    \n",
    "train_p = train_p.cpu().flatten(1,2).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sequence(vertices, faces, frame_interval=40):\n",
    "    scene = trimesh.Scene()\n",
    "    for i in list(range(0, vertices.shape[0]-1, frame_interval)) + [vertices.shape[0]-1]:\n",
    "        mesh = trimesh.Trimesh(vertices=vertices[i, :, :].detach().cpu(), faces=faces, process=False)\n",
    "        scene.add_geometry(mesh)\n",
    "    return display(scene.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0].data\n",
    "values = dataset.body_model(data)\n",
    "show_sequence(values.cpu(), dataset.smpl_faces.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[1].data\n",
    "values = dataset.body_model(data)\n",
    "show_sequence(values.cpu(), dataset.smpl_faces.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[2].data\n",
    "values = dataset.body_model(data)\n",
    "show_sequence(values.cpu(), dataset.smpl_faces.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgarment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
